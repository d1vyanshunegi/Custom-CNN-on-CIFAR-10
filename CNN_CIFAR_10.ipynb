{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O5TJ_7RLPn-d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Device Configuration\n",
        "# ------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "ezBHQCOoP66X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Residual Block Definition\n",
        "# ------------------------------\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "CVq6rwrkP-1X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Custom ResNet Model for CIFAR-10\n",
        "# ------------------------------\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        # Initial convolution for CIFAR-10 (3-channel images)\n",
        "        self.conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # Define layers using residual blocks\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        # If input and output dimensions differ, downsample to match them\n",
        "        if stride != 1 or self.in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "def get_resnet18():\n",
        "    # ResNet-18 uses [2, 2, 2, 2] residual blocks in each layer\n",
        "    return CustomResNet(ResidualBlock, [2, 2, 2, 2])\n"
      ],
      "metadata": {
        "id": "5OL6CQb-QERZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Main Training Script\n",
        "# ------------------------------\n",
        "def main():\n",
        "    # Hyperparameters\n",
        "    num_epochs = 30\n",
        "    batch_size = 128\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Data augmentation and normalization for training\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ])\n",
        "\n",
        "    # Normalization for testing\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ])\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                                 download=True, transform=transform_train)\n",
        "    test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                                download=True, transform=transform_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                             shuffle=False, num_workers=2)\n",
        "\n",
        "      # Initialize the model, loss function, optimizer, and learning rate scheduler\n",
        "    model = get_resnet18().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # ----- Forward Pass -----\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # ----- Backward Pass and Optimization -----\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Adjust learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # ----- Evaluation on Test Set -----\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        # Save the best model based on test accuracy\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            torch.save(model.state_dict(), \"best_resnet18_cifar10.pth\")\n",
        "            print(\"Saved Best Model with Accuracy: {:.2f}%\".format(best_accuracy))"
      ],
      "metadata": {
        "id": "h8qQIJWzQIRv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCJHnpOlQqVn",
        "outputId": "5838b015-0316-443f-b109-9d260f53a3fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch [1/30], Step [100/391], Loss: 1.7875\n",
            "Epoch [1/30], Step [200/391], Loss: 1.4672\n",
            "Epoch [1/30], Step [300/391], Loss: 1.2844\n",
            "Epoch [1/30], Test Accuracy: 57.77%\n",
            "Saved Best Model with Accuracy: 57.77%\n",
            "Epoch [2/30], Step [100/391], Loss: 1.0326\n",
            "Epoch [2/30], Step [200/391], Loss: 0.9832\n",
            "Epoch [2/30], Step [300/391], Loss: 0.9265\n",
            "Epoch [2/30], Test Accuracy: 69.39%\n",
            "Saved Best Model with Accuracy: 69.39%\n",
            "Epoch [3/30], Step [100/391], Loss: 0.8052\n",
            "Epoch [3/30], Step [200/391], Loss: 0.7732\n",
            "Epoch [3/30], Step [300/391], Loss: 0.7104\n",
            "Epoch [3/30], Test Accuracy: 70.08%\n",
            "Saved Best Model with Accuracy: 70.08%\n",
            "Epoch [4/30], Step [100/391], Loss: 0.6403\n",
            "Epoch [4/30], Step [200/391], Loss: 0.6347\n",
            "Epoch [4/30], Step [300/391], Loss: 0.6082\n",
            "Epoch [4/30], Test Accuracy: 80.10%\n",
            "Saved Best Model with Accuracy: 80.10%\n",
            "Epoch [5/30], Step [100/391], Loss: 0.5490\n",
            "Epoch [5/30], Step [200/391], Loss: 0.5506\n",
            "Epoch [5/30], Step [300/391], Loss: 0.5333\n",
            "Epoch [5/30], Test Accuracy: 79.20%\n",
            "Epoch [6/30], Step [100/391], Loss: 0.4899\n",
            "Epoch [6/30], Step [200/391], Loss: 0.4868\n",
            "Epoch [6/30], Step [300/391], Loss: 0.4706\n",
            "Epoch [6/30], Test Accuracy: 78.00%\n",
            "Epoch [7/30], Step [100/391], Loss: 0.4452\n",
            "Epoch [7/30], Step [200/391], Loss: 0.4196\n",
            "Epoch [7/30], Step [300/391], Loss: 0.4174\n",
            "Epoch [7/30], Test Accuracy: 84.13%\n",
            "Saved Best Model with Accuracy: 84.13%\n",
            "Epoch [8/30], Step [100/391], Loss: 0.3883\n",
            "Epoch [8/30], Step [200/391], Loss: 0.3799\n",
            "Epoch [8/30], Step [300/391], Loss: 0.3892\n",
            "Epoch [8/30], Test Accuracy: 82.86%\n",
            "Epoch [9/30], Step [100/391], Loss: 0.3427\n",
            "Epoch [9/30], Step [200/391], Loss: 0.3665\n",
            "Epoch [9/30], Step [300/391], Loss: 0.3470\n",
            "Epoch [9/30], Test Accuracy: 85.65%\n",
            "Saved Best Model with Accuracy: 85.65%\n",
            "Epoch [10/30], Step [100/391], Loss: 0.3092\n",
            "Epoch [10/30], Step [200/391], Loss: 0.3402\n",
            "Epoch [10/30], Step [300/391], Loss: 0.3476\n",
            "Epoch [10/30], Test Accuracy: 86.02%\n",
            "Saved Best Model with Accuracy: 86.02%\n",
            "Epoch [11/30], Step [100/391], Loss: 0.2501\n",
            "Epoch [11/30], Step [200/391], Loss: 0.2140\n",
            "Epoch [11/30], Step [300/391], Loss: 0.2134\n",
            "Epoch [11/30], Test Accuracy: 89.97%\n",
            "Saved Best Model with Accuracy: 89.97%\n",
            "Epoch [12/30], Step [100/391], Loss: 0.1915\n",
            "Epoch [12/30], Step [200/391], Loss: 0.1883\n",
            "Epoch [12/30], Step [300/391], Loss: 0.1933\n",
            "Epoch [12/30], Test Accuracy: 90.14%\n",
            "Saved Best Model with Accuracy: 90.14%\n",
            "Epoch [13/30], Step [100/391], Loss: 0.1881\n",
            "Epoch [13/30], Step [200/391], Loss: 0.1757\n",
            "Epoch [13/30], Step [300/391], Loss: 0.1799\n",
            "Epoch [13/30], Test Accuracy: 90.55%\n",
            "Saved Best Model with Accuracy: 90.55%\n",
            "Epoch [14/30], Step [100/391], Loss: 0.1620\n",
            "Epoch [14/30], Step [200/391], Loss: 0.1680\n",
            "Epoch [14/30], Step [300/391], Loss: 0.1665\n",
            "Epoch [14/30], Test Accuracy: 90.27%\n",
            "Epoch [15/30], Step [100/391], Loss: 0.1646\n",
            "Epoch [15/30], Step [200/391], Loss: 0.1526\n",
            "Epoch [15/30], Step [300/391], Loss: 0.1565\n",
            "Epoch [15/30], Test Accuracy: 90.63%\n",
            "Saved Best Model with Accuracy: 90.63%\n",
            "Epoch [16/30], Step [100/391], Loss: 0.1483\n",
            "Epoch [16/30], Step [200/391], Loss: 0.1515\n",
            "Epoch [16/30], Step [300/391], Loss: 0.1566\n",
            "Epoch [16/30], Test Accuracy: 90.66%\n",
            "Saved Best Model with Accuracy: 90.66%\n",
            "Epoch [17/30], Step [100/391], Loss: 0.1353\n",
            "Epoch [17/30], Step [200/391], Loss: 0.1352\n",
            "Epoch [17/30], Step [300/391], Loss: 0.1501\n",
            "Epoch [17/30], Test Accuracy: 90.67%\n",
            "Saved Best Model with Accuracy: 90.67%\n",
            "Epoch [18/30], Step [100/391], Loss: 0.1295\n",
            "Epoch [18/30], Step [200/391], Loss: 0.1400\n",
            "Epoch [18/30], Step [300/391], Loss: 0.1351\n",
            "Epoch [18/30], Test Accuracy: 90.51%\n",
            "Epoch [19/30], Step [100/391], Loss: 0.1237\n",
            "Epoch [19/30], Step [200/391], Loss: 0.1259\n",
            "Epoch [19/30], Step [300/391], Loss: 0.1273\n",
            "Epoch [19/30], Test Accuracy: 90.57%\n",
            "Epoch [20/30], Step [100/391], Loss: 0.1183\n",
            "Epoch [20/30], Step [200/391], Loss: 0.1229\n",
            "Epoch [20/30], Step [300/391], Loss: 0.1217\n",
            "Epoch [20/30], Test Accuracy: 91.00%\n",
            "Saved Best Model with Accuracy: 91.00%\n",
            "Epoch [21/30], Step [100/391], Loss: 0.1101\n",
            "Epoch [21/30], Step [200/391], Loss: 0.1039\n",
            "Epoch [21/30], Step [300/391], Loss: 0.0994\n",
            "Epoch [21/30], Test Accuracy: 91.15%\n",
            "Saved Best Model with Accuracy: 91.15%\n",
            "Epoch [22/30], Step [100/391], Loss: 0.1033\n",
            "Epoch [22/30], Step [200/391], Loss: 0.1012\n",
            "Epoch [22/30], Step [300/391], Loss: 0.0987\n",
            "Epoch [22/30], Test Accuracy: 91.17%\n",
            "Saved Best Model with Accuracy: 91.17%\n",
            "Epoch [23/30], Step [100/391], Loss: 0.0971\n",
            "Epoch [23/30], Step [200/391], Loss: 0.0999\n",
            "Epoch [23/30], Step [300/391], Loss: 0.0936\n",
            "Epoch [23/30], Test Accuracy: 91.27%\n",
            "Saved Best Model with Accuracy: 91.27%\n",
            "Epoch [24/30], Step [100/391], Loss: 0.0917\n",
            "Epoch [24/30], Step [200/391], Loss: 0.0957\n",
            "Epoch [24/30], Step [300/391], Loss: 0.1012\n",
            "Epoch [24/30], Test Accuracy: 91.37%\n",
            "Saved Best Model with Accuracy: 91.37%\n",
            "Epoch [25/30], Step [100/391], Loss: 0.0921\n",
            "Epoch [25/30], Step [200/391], Loss: 0.1030\n",
            "Epoch [25/30], Step [300/391], Loss: 0.0944\n",
            "Epoch [25/30], Test Accuracy: 91.35%\n",
            "Epoch [26/30], Step [100/391], Loss: 0.1003\n",
            "Epoch [26/30], Step [200/391], Loss: 0.0962\n",
            "Epoch [26/30], Step [300/391], Loss: 0.0974\n",
            "Epoch [26/30], Test Accuracy: 91.25%\n",
            "Epoch [27/30], Step [100/391], Loss: 0.0930\n",
            "Epoch [27/30], Step [200/391], Loss: 0.0976\n",
            "Epoch [27/30], Step [300/391], Loss: 0.0919\n",
            "Epoch [27/30], Test Accuracy: 91.33%\n",
            "Epoch [28/30], Step [100/391], Loss: 0.0963\n",
            "Epoch [28/30], Step [200/391], Loss: 0.0971\n",
            "Epoch [28/30], Step [300/391], Loss: 0.0920\n",
            "Epoch [28/30], Test Accuracy: 91.33%\n",
            "Epoch [29/30], Step [100/391], Loss: 0.0967\n",
            "Epoch [29/30], Step [200/391], Loss: 0.0921\n",
            "Epoch [29/30], Step [300/391], Loss: 0.0875\n",
            "Epoch [29/30], Test Accuracy: 91.32%\n",
            "Epoch [30/30], Step [100/391], Loss: 0.0959\n",
            "Epoch [30/30], Step [200/391], Loss: 0.0856\n",
            "Epoch [30/30], Step [300/391], Loss: 0.0854\n",
            "Epoch [30/30], Test Accuracy: 91.20%\n"
          ]
        }
      ]
    }
  ]
}